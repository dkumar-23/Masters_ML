{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dkumar-23/Masters_ML/blob/main/DNN_Assignment_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1VG8BU_w3syy"
      },
      "source": [
        "# Deep Neural Networks - Programming Assignment\n",
        "## Comparing Linear Models and Multi-Layer Perceptrons\n",
        "\n",
        "**Student Name:** DIPESH KUMAR\n",
        "\n",
        "**Student ID:** 2025ab05034\n",
        "\n",
        "**Date:** 1st Dec, 2025\n",
        "\n",
        "---\n",
        "\n",
        "## ⚠️ IMPORTANT INSTRUCTIONS\n",
        "\n",
        "1. **Complete ALL sections** marked with `TODO`\n",
        "2. **DO NOT modify** the `get_assignment_results()` function structure\n",
        "3. **Fill in all values accurately** - these will be auto-verified\n",
        "4. **After submission**, you'll receive a verification quiz based on YOUR results\n",
        "5. **Run all cells** before submitting (Kernel → Restart & Run All)\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hTxcZR3i3sy1",
        "outputId": "39abad98-e06e-4a9d-9c6f-121c3d007e8f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ Libraries imported successfully\n"
          ]
        }
      ],
      "source": [
        "# Import required libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import time\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "np.random.seed(42)\n",
        "print('✓ Libraries imported successfully')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YIXcFuj23sy4"
      },
      "source": [
        "## Section 1: Dataset Selection and Loading\n",
        "\n",
        "**Requirements:**\n",
        "- ≥500 samples\n",
        "- ≥5 features\n",
        "- Public dataset (UCI/Kaggle)\n",
        "- Regression OR Classification problem"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: Load your dataset\n",
        "data = pd.read_csv('/content/Cancer_Data.csv')"
      ],
      "metadata": {
        "id": "_wdmshQp6SSh"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 273
        },
        "id": "xN5z1IFv6UDb",
        "outputId": "ee2d7451-7841-477a-8e50-8017cface5ba"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         id diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
              "0    842302         M        17.99         10.38          122.80     1001.0   \n",
              "1    842517         M        20.57         17.77          132.90     1326.0   \n",
              "2  84300903         M        19.69         21.25          130.00     1203.0   \n",
              "3  84348301         M        11.42         20.38           77.58      386.1   \n",
              "4  84358402         M        20.29         14.34          135.10     1297.0   \n",
              "\n",
              "   smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
              "0          0.11840           0.27760          0.3001              0.14710   \n",
              "1          0.08474           0.07864          0.0869              0.07017   \n",
              "2          0.10960           0.15990          0.1974              0.12790   \n",
              "3          0.14250           0.28390          0.2414              0.10520   \n",
              "4          0.10030           0.13280          0.1980              0.10430   \n",
              "\n",
              "   ...  texture_worst  perimeter_worst  area_worst  smoothness_worst  \\\n",
              "0  ...          17.33           184.60      2019.0            0.1622   \n",
              "1  ...          23.41           158.80      1956.0            0.1238   \n",
              "2  ...          25.53           152.50      1709.0            0.1444   \n",
              "3  ...          26.50            98.87       567.7            0.2098   \n",
              "4  ...          16.67           152.20      1575.0            0.1374   \n",
              "\n",
              "   compactness_worst  concavity_worst  concave points_worst  symmetry_worst  \\\n",
              "0             0.6656           0.7119                0.2654          0.4601   \n",
              "1             0.1866           0.2416                0.1860          0.2750   \n",
              "2             0.4245           0.4504                0.2430          0.3613   \n",
              "3             0.8663           0.6869                0.2575          0.6638   \n",
              "4             0.2050           0.4000                0.1625          0.2364   \n",
              "\n",
              "   fractal_dimension_worst  Unnamed: 32  \n",
              "0                  0.11890          NaN  \n",
              "1                  0.08902          NaN  \n",
              "2                  0.08758          NaN  \n",
              "3                  0.17300          NaN  \n",
              "4                  0.07678          NaN  \n",
              "\n",
              "[5 rows x 33 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-fcb4cca9-2fa5-4e23-b4d3-30f7858e206b\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>diagnosis</th>\n",
              "      <th>radius_mean</th>\n",
              "      <th>texture_mean</th>\n",
              "      <th>perimeter_mean</th>\n",
              "      <th>area_mean</th>\n",
              "      <th>smoothness_mean</th>\n",
              "      <th>compactness_mean</th>\n",
              "      <th>concavity_mean</th>\n",
              "      <th>concave points_mean</th>\n",
              "      <th>...</th>\n",
              "      <th>texture_worst</th>\n",
              "      <th>perimeter_worst</th>\n",
              "      <th>area_worst</th>\n",
              "      <th>smoothness_worst</th>\n",
              "      <th>compactness_worst</th>\n",
              "      <th>concavity_worst</th>\n",
              "      <th>concave points_worst</th>\n",
              "      <th>symmetry_worst</th>\n",
              "      <th>fractal_dimension_worst</th>\n",
              "      <th>Unnamed: 32</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>842302</td>\n",
              "      <td>M</td>\n",
              "      <td>17.99</td>\n",
              "      <td>10.38</td>\n",
              "      <td>122.80</td>\n",
              "      <td>1001.0</td>\n",
              "      <td>0.11840</td>\n",
              "      <td>0.27760</td>\n",
              "      <td>0.3001</td>\n",
              "      <td>0.14710</td>\n",
              "      <td>...</td>\n",
              "      <td>17.33</td>\n",
              "      <td>184.60</td>\n",
              "      <td>2019.0</td>\n",
              "      <td>0.1622</td>\n",
              "      <td>0.6656</td>\n",
              "      <td>0.7119</td>\n",
              "      <td>0.2654</td>\n",
              "      <td>0.4601</td>\n",
              "      <td>0.11890</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>842517</td>\n",
              "      <td>M</td>\n",
              "      <td>20.57</td>\n",
              "      <td>17.77</td>\n",
              "      <td>132.90</td>\n",
              "      <td>1326.0</td>\n",
              "      <td>0.08474</td>\n",
              "      <td>0.07864</td>\n",
              "      <td>0.0869</td>\n",
              "      <td>0.07017</td>\n",
              "      <td>...</td>\n",
              "      <td>23.41</td>\n",
              "      <td>158.80</td>\n",
              "      <td>1956.0</td>\n",
              "      <td>0.1238</td>\n",
              "      <td>0.1866</td>\n",
              "      <td>0.2416</td>\n",
              "      <td>0.1860</td>\n",
              "      <td>0.2750</td>\n",
              "      <td>0.08902</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>84300903</td>\n",
              "      <td>M</td>\n",
              "      <td>19.69</td>\n",
              "      <td>21.25</td>\n",
              "      <td>130.00</td>\n",
              "      <td>1203.0</td>\n",
              "      <td>0.10960</td>\n",
              "      <td>0.15990</td>\n",
              "      <td>0.1974</td>\n",
              "      <td>0.12790</td>\n",
              "      <td>...</td>\n",
              "      <td>25.53</td>\n",
              "      <td>152.50</td>\n",
              "      <td>1709.0</td>\n",
              "      <td>0.1444</td>\n",
              "      <td>0.4245</td>\n",
              "      <td>0.4504</td>\n",
              "      <td>0.2430</td>\n",
              "      <td>0.3613</td>\n",
              "      <td>0.08758</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>84348301</td>\n",
              "      <td>M</td>\n",
              "      <td>11.42</td>\n",
              "      <td>20.38</td>\n",
              "      <td>77.58</td>\n",
              "      <td>386.1</td>\n",
              "      <td>0.14250</td>\n",
              "      <td>0.28390</td>\n",
              "      <td>0.2414</td>\n",
              "      <td>0.10520</td>\n",
              "      <td>...</td>\n",
              "      <td>26.50</td>\n",
              "      <td>98.87</td>\n",
              "      <td>567.7</td>\n",
              "      <td>0.2098</td>\n",
              "      <td>0.8663</td>\n",
              "      <td>0.6869</td>\n",
              "      <td>0.2575</td>\n",
              "      <td>0.6638</td>\n",
              "      <td>0.17300</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>84358402</td>\n",
              "      <td>M</td>\n",
              "      <td>20.29</td>\n",
              "      <td>14.34</td>\n",
              "      <td>135.10</td>\n",
              "      <td>1297.0</td>\n",
              "      <td>0.10030</td>\n",
              "      <td>0.13280</td>\n",
              "      <td>0.1980</td>\n",
              "      <td>0.10430</td>\n",
              "      <td>...</td>\n",
              "      <td>16.67</td>\n",
              "      <td>152.20</td>\n",
              "      <td>1575.0</td>\n",
              "      <td>0.1374</td>\n",
              "      <td>0.2050</td>\n",
              "      <td>0.4000</td>\n",
              "      <td>0.1625</td>\n",
              "      <td>0.2364</td>\n",
              "      <td>0.07678</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 33 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fcb4cca9-2fa5-4e23-b4d3-30f7858e206b')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-fcb4cca9-2fa5-4e23-b4d3-30f7858e206b button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-fcb4cca9-2fa5-4e23-b4d3-30f7858e206b');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-66d96dbd-e52a-463a-a6c7-e0daec5fa920\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-66d96dbd-e52a-463a-a6c7-e0daec5fa920')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-66d96dbd-e52a-463a-a6c7-e0daec5fa920 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "data"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "McqygcgE9dSZ",
        "outputId": "da29161d-3808-4ee4-a121-819b3f535357"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(569, 33)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OfbN4Buf3sy5",
        "outputId": "4ac042f2-100e-4592-ae10-378db083238c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset: Breast Cancer Data Set\n",
            "Source: https://www.kaggle.com/datasets/erdemtaha/cancer-data\n",
            "Samples: 569, Features: 31\n",
            "Problem Type: binary_classification\n",
            "Primary Metric: recall\n"
          ]
        }
      ],
      "source": [
        "# Dataset information (TODO: Fill these)\n",
        "dataset_name = \"Breast Cancer Data Set\"  #Breast Cancer Data Set\n",
        "dataset_source = \"https://www.kaggle.com/datasets/erdemtaha/cancer-data\"  #Kaggle\n",
        "n_samples = 569      # Total number of rows\n",
        "n_features = 31     # Number of features (excluding target i.e. 'diagnosis')\n",
        "problem_type = \"binary_classification\"\n",
        "\n",
        "# Problem statement (TODO: Write 2-3 sentences)\n",
        "problem_statement = \"\"\"\n",
        "TODO: Predicting tumor malignancy from diagnostic measurements.\n",
        "This is critical for early cancer detection in medical diagnosis, enabling timely intervention and improving patient outcomes.'\"\n",
        "\"\"\"\n",
        "\n",
        "# Primary evaluation metric (TODO: Fill this)\n",
        "primary_metric = \"recall\"\n",
        "\n",
        "# Metric justification (TODO: Write 2-3 sentences)\n",
        "metric_justification = \"\"\"\n",
        "TODO: I chose recall because in medical diagnosis, false negatives (missing cancer) are more costly than false positives,\n",
        "which is crucial for early detection and timely intervention.\"\n",
        "\"\"\"\n",
        "\n",
        "print(f\"Dataset: {dataset_name}\")\n",
        "print(f\"Source: {dataset_source}\")\n",
        "print(f\"Samples: {n_samples}, Features: {n_features}\")\n",
        "print(f\"Problem Type: {problem_type}\")\n",
        "print(f\"Primary Metric: {primary_metric}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jM5ZA7tS3sy5"
      },
      "source": [
        "## Section 2: Data Preprocessing\n",
        "\n",
        "Preprocess your data:\n",
        "1. Handle missing values\n",
        "2. Encode categorical variables\n",
        "3. Split into train/test sets\n",
        "4. Scale features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p6hnDjJf3sy6",
        "outputId": "7095fbde-f413-4205-85db-a2c4fd48294b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Features (X) and target (y) separated and target encoded.\n",
            "X shape: (569, 30)\n",
            "y shape: (569,)\n",
            "No missing values found in the feature DataFrame (X).\n",
            "Train samples: 455\n",
            "Test samples: 114\n",
            "Split ratio: 80.0%\n",
            "X_train_scaled shape: (455, 30)\n",
            "X_test_scaled shape: (114, 30)\n"
          ]
        }
      ],
      "source": [
        "# TODO: Preprocess your data\n",
        "data = data.drop(columns=['id', 'Unnamed: 32'], errors='ignore')\n",
        "X = data.drop('diagnosis', axis=1)\n",
        "y = data['diagnosis'].map({'M': 1, 'B': 0})\n",
        "\n",
        "print(\"Features (X) and target (y) separated and target encoded.\")\n",
        "print(f\"X shape: {X.shape}\")\n",
        "print(f\"y shape: {y.shape}\")\n",
        "\n",
        "missing_values = X.isnull().sum()\n",
        "\n",
        "if missing_values.sum() == 0:\n",
        "    print(\"No missing values found in the feature DataFrame (X).\")\n",
        "else:\n",
        "    print(\"Missing values in feature DataFrame (X) per column:\")\n",
        "    print(missing_values[missing_values > 0])\n",
        "\n",
        "# TODO: Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# TODO: Feature scaling\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Fill these after preprocessing\n",
        "train_samples = X_train_scaled.shape[0]       # Number of training samples\n",
        "test_samples = X_test_scaled.shape[0]        # Number of test samples\n",
        "train_test_ratio = train_samples / (train_samples + test_samples) # e.g., 0.8 for 80-20 split\n",
        "\n",
        "print(f\"Train samples: {train_samples}\")\n",
        "print(f\"Test samples: {test_samples}\")\n",
        "print(f\"Split ratio: {train_test_ratio:.1%}\")\n",
        "print(f\"X_train_scaled shape: {X_train_scaled.shape}\")\n",
        "print(f\"X_test_scaled shape: {X_test_scaled.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "62df98f3"
      },
      "source": [
        "## Train-Test Split\n",
        "\n",
        "### Subtask:\n",
        "Split the preprocessed features (X) and target (y) into training and testing sets, and update the sample count variables."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "olIIofBN3sy7"
      },
      "source": [
        "## Section 3: Baseline Model Implementation\n",
        "\n",
        "Implement from scratch (NO sklearn models!):\n",
        "- Linear Regression (for regression)\n",
        "- Logistic Regression (for binary classification)\n",
        "- Softmax Regression (for multiclass classification)\n",
        "\n",
        "**Must include:**\n",
        "- Forward pass (prediction)\n",
        "- Loss computation\n",
        "- Gradient computation\n",
        "- Gradient descent loop\n",
        "- Loss tracking"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TXjIq0Dl3sy8"
      },
      "outputs": [],
      "source": [
        "class BaselineModel:\n",
        "    \"\"\"\n",
        "    Baseline linear model with gradient descent\n",
        "    Implement: Linear/Logistic/Softmax Regression\n",
        "    \"\"\"\n",
        "    def __init__(self, learning_rate=0.01, n_iterations=1000):\n",
        "        self.lr = learning_rate\n",
        "        self.n_iterations = n_iterations\n",
        "        self.weights = None\n",
        "        self.bias = None\n",
        "        self.loss_history = []\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        \"\"\"\n",
        "        TODO: Implement gradient descent training\n",
        "\n",
        "        Steps:\n",
        "        1. Initialize weights and bias\n",
        "        2. For each iteration:\n",
        "           a. Compute predictions (forward pass)\n",
        "           b. Compute loss\n",
        "           c. Compute gradients\n",
        "           d. Update weights and bias\n",
        "           e. Store loss in self.loss_history\n",
        "\n",
        "        Must populate self.loss_history with loss at each iteration!\n",
        "        \"\"\"\n",
        "        n_samples, n_features = X.shape\n",
        "\n",
        "        # TODO: Initialize parameters\n",
        "        self.weights = np.zeros(n_features)\n",
        "        self.bias = 0\n",
        "\n",
        "        # TODO: Implement gradient descent loop\n",
        "        for i in range(self.n_iterations):\n",
        "            # 1. Forward pass: y_pred = ...\n",
        "            # 2. Compute loss\n",
        "            # 3. Compute gradients: dw = ..., db = ...\n",
        "            # 4. Update: self.weights -= self.lr * dw\n",
        "            # 5. self.loss_history.append(loss)\n",
        "\n",
        "            pass  # Replace with your implementation\n",
        "\n",
        "        return self\n",
        "\n",
        "    def predict(self, X):\n",
        "        \"\"\"\n",
        "        TODO: Implement prediction\n",
        "\n",
        "        For regression: return linear_output\n",
        "        For classification: return class probabilities or labels\n",
        "        \"\"\"\n",
        "        pass  # Replace with your implementation\n",
        "\n",
        "print(\"✓ Baseline model class defined\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zj-4fJWg3sy9"
      },
      "outputs": [],
      "source": [
        "# Train baseline model\n",
        "print(\"Training baseline model...\")\n",
        "baseline_start_time = time.time()\n",
        "\n",
        "# TODO: Initialize and train your baseline model\n",
        "baseline_model = BaselineModel(learning_rate=0.01, n_iterations=1000)\n",
        "# baseline_model.fit(X_train_scaled, y_train)\n",
        "\n",
        "# TODO: Make predictions\n",
        "# baseline_predictions = baseline_model.predict(X_test_scaled)\n",
        "\n",
        "baseline_training_time = time.time() - baseline_start_time\n",
        "print(f\"✓ Baseline training completed in {baseline_training_time:.2f}s\")\n",
        "print(f\"✓ Loss decreased from {baseline_model.loss_history[0]:.4f} to {baseline_model.loss_history[-1]:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sS1mZNf33sy-"
      },
      "source": [
        "## Section 4: Multi-Layer Perceptron Implementation\n",
        "\n",
        "Implement MLP from scratch with:\n",
        "- At least 1 hidden layer\n",
        "- ReLU activation for hidden layers\n",
        "- Appropriate output activation\n",
        "- Forward propagation\n",
        "- Backward propagation\n",
        "- Gradient descent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DRjjddxB3sy_"
      },
      "outputs": [],
      "source": [
        "class MLP:\n",
        "    \"\"\"\n",
        "    Multi-Layer Perceptron implemented from scratch\n",
        "    \"\"\"\n",
        "    def __init__(self, architecture, learning_rate=0.01, n_iterations=1000):\n",
        "        \"\"\"\n",
        "        architecture: list [input_size, hidden1, hidden2, ..., output_size]\n",
        "        Example: [30, 16, 8, 1] means:\n",
        "            - 30 input features\n",
        "            - Hidden layer 1: 16 neurons\n",
        "            - Hidden layer 2: 8 neurons\n",
        "            - Output layer: 1 neuron\n",
        "        \"\"\"\n",
        "        self.architecture = architecture\n",
        "        self.lr = learning_rate\n",
        "        self.n_iterations = n_iterations\n",
        "        self.parameters = {}\n",
        "        self.loss_history = []\n",
        "        self.cache = {}\n",
        "\n",
        "    def initialize_parameters(self):\n",
        "        \"\"\"\n",
        "        TODO: Initialize weights and biases for all layers\n",
        "\n",
        "        For each layer l:\n",
        "        - W[l]: weight matrix of shape (n[l], n[l-1])\n",
        "        - b[l]: bias vector of shape (n[l], 1)\n",
        "\n",
        "        Store in self.parameters dictionary\n",
        "        \"\"\"\n",
        "        np.random.seed(42)\n",
        "\n",
        "        for l in range(1, len(self.architecture)):\n",
        "            # TODO: Initialize weights and biases\n",
        "            # self.parameters[f'W{l}'] = ...\n",
        "            # self.parameters[f'b{l}'] = ...\n",
        "            pass\n",
        "\n",
        "    def relu(self, Z):\n",
        "        \"\"\"ReLU activation function\"\"\"\n",
        "        return np.maximum(0, Z)\n",
        "\n",
        "    def relu_derivative(self, Z):\n",
        "        \"\"\"ReLU derivative\"\"\"\n",
        "        return (Z > 0).astype(float)\n",
        "\n",
        "    def sigmoid(self, Z):\n",
        "        \"\"\"Sigmoid activation (for binary classification output)\"\"\"\n",
        "        return 1 / (1 + np.exp(-np.clip(Z, -500, 500)))\n",
        "\n",
        "    def forward_propagation(self, X):\n",
        "        \"\"\"\n",
        "        TODO: Implement forward pass through all layers\n",
        "\n",
        "        For each layer:\n",
        "        1. Z[l] = W[l] @ A[l-1] + b[l]\n",
        "        2. A[l] = activation(Z[l])\n",
        "\n",
        "        Store Z and A in self.cache for backpropagation\n",
        "        Return final activation A[L]\n",
        "        \"\"\"\n",
        "        self.cache['A0'] = X\n",
        "\n",
        "        # TODO: Implement forward pass\n",
        "        # for l in range(1, len(self.architecture)):\n",
        "        #     ...\n",
        "\n",
        "        pass  # Replace with your implementation\n",
        "\n",
        "    def backward_propagation(self, X, y):\n",
        "        \"\"\"\n",
        "        TODO: Implement backward pass to compute gradients\n",
        "\n",
        "        Starting from output layer, compute:\n",
        "        1. dZ[l] for each layer\n",
        "        2. dW[l] = dZ[l] @ A[l-1].T / m\n",
        "        3. db[l] = sum(dZ[l]) / m\n",
        "\n",
        "        Return dictionary of gradients\n",
        "        \"\"\"\n",
        "        m = X.shape[0]\n",
        "        grads = {}\n",
        "\n",
        "        # TODO: Implement backward pass\n",
        "        # Start with output layer gradient\n",
        "        # Then propagate backwards through hidden layers\n",
        "\n",
        "        pass  # Replace with your implementation\n",
        "\n",
        "        return grads\n",
        "\n",
        "    def update_parameters(self, grads):\n",
        "        \"\"\"\n",
        "        TODO: Update weights and biases using gradients\n",
        "\n",
        "        For each layer:\n",
        "        W[l] = W[l] - learning_rate * dW[l]\n",
        "        b[l] = b[l] - learning_rate * db[l]\n",
        "        \"\"\"\n",
        "        # TODO: Implement parameter updates\n",
        "        pass\n",
        "\n",
        "    def compute_loss(self, y_pred, y_true):\n",
        "        \"\"\"\n",
        "        TODO: Compute loss\n",
        "\n",
        "        For regression: MSE\n",
        "        For classification: Cross-entropy\n",
        "        \"\"\"\n",
        "        pass  # Replace with your implementation\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        \"\"\"\n",
        "        TODO: Implement training loop\n",
        "\n",
        "        For each iteration:\n",
        "        1. Forward propagation\n",
        "        2. Compute loss\n",
        "        3. Backward propagation\n",
        "        4. Update parameters\n",
        "        5. Store loss\n",
        "\n",
        "        Must populate self.loss_history!\n",
        "        \"\"\"\n",
        "        self.initialize_parameters()\n",
        "\n",
        "        for i in range(self.n_iterations):\n",
        "            # TODO: Training loop\n",
        "            pass\n",
        "\n",
        "        return self\n",
        "\n",
        "    def predict(self, X):\n",
        "        \"\"\"\n",
        "        TODO: Implement prediction\n",
        "\n",
        "        Use forward_propagation and apply appropriate thresholding\n",
        "        \"\"\"\n",
        "        pass  # Replace with your implementation\n",
        "\n",
        "print(\"✓ MLP class defined\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PQKaejwj3szA"
      },
      "outputs": [],
      "source": [
        "# Train MLP\n",
        "print(\"Training MLP...\")\n",
        "mlp_start_time = time.time()\n",
        "\n",
        "# TODO: Define your architecture and train MLP\n",
        "mlp_architecture = []  # Example: [n_features, 16, 8, 1]\n",
        "mlp_model = MLP(architecture=mlp_architecture, learning_rate=0.01, n_iterations=1000)\n",
        "# mlp_model.fit(X_train_scaled, y_train)\n",
        "\n",
        "# TODO: Make predictions\n",
        "# mlp_predictions = mlp_model.predict(X_test_scaled)\n",
        "\n",
        "mlp_training_time = time.time() - mlp_start_time\n",
        "print(f\"✓ MLP training completed in {mlp_training_time:.2f}s\")\n",
        "print(f\"✓ Loss decreased from {mlp_model.loss_history[0]:.4f} to {mlp_model.loss_history[-1]:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1brRsdI23szB"
      },
      "source": [
        "## Section 5: Evaluation and Metrics\n",
        "\n",
        "Calculate appropriate metrics for your problem type"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fz9Si9HG3szB"
      },
      "outputs": [],
      "source": [
        "def calculate_metrics(y_true, y_pred, problem_type):\n",
        "    \"\"\"\n",
        "    TODO: Calculate appropriate metrics based on problem type\n",
        "\n",
        "    For regression: MSE, RMSE, MAE, R²\n",
        "    For classification: Accuracy, Precision, Recall, F1\n",
        "    \"\"\"\n",
        "    metrics = {}\n",
        "\n",
        "    if problem_type == \"regression\":\n",
        "        # TODO: Calculate regression metrics\n",
        "        pass\n",
        "    elif problem_type in [\"binary_classification\", \"multiclass_classification\"]:\n",
        "        # TODO: Calculate classification metrics\n",
        "        pass\n",
        "\n",
        "    return metrics\n",
        "\n",
        "# Calculate metrics for both models\n",
        "# baseline_metrics = calculate_metrics(y_test, baseline_predictions, problem_type)\n",
        "# mlp_metrics = calculate_metrics(y_test, mlp_predictions, problem_type)\n",
        "\n",
        "print(\"Baseline Model Performance:\")\n",
        "# print(baseline_metrics)\n",
        "\n",
        "print(\"\\nMLP Model Performance:\")\n",
        "# print(mlp_metrics)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PRbI_ATe3szC"
      },
      "source": [
        "## Section 6: Visualization\n",
        "\n",
        "Create visualizations:\n",
        "1. Training loss curves\n",
        "2. Performance comparison\n",
        "3. Additional domain-specific plots"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QbfxB35I3szC"
      },
      "outputs": [],
      "source": [
        "# 1. Training loss curves\n",
        "plt.figure(figsize=(14, 5))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "# TODO: Plot baseline loss\n",
        "# plt.plot(baseline_model.loss_history, label='Baseline', color='blue')\n",
        "plt.xlabel('Iteration')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Baseline Model - Training Loss')\n",
        "plt.legend()\n",
        "plt.grid(True, alpha=0.3)\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "# TODO: Plot MLP loss\n",
        "# plt.plot(mlp_model.loss_history, label='MLP', color='red')\n",
        "plt.xlabel('Iteration')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('MLP Model - Training Loss')\n",
        "plt.legend()\n",
        "plt.grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eVHx24MA3szC"
      },
      "outputs": [],
      "source": [
        "# 2. Performance comparison bar chart\n",
        "# TODO: Create bar chart comparing key metrics between models\n",
        "plt.figure(figsize=(10, 6))\n",
        "\n",
        "# Example:\n",
        "# metrics = ['Accuracy', 'Precision', 'Recall', 'F1']\n",
        "# baseline_scores = [baseline_metrics[m] for m in metrics]\n",
        "# mlp_scores = [mlp_metrics[m] for m in metrics]\n",
        "#\n",
        "# x = np.arange(len(metrics))\n",
        "# width = 0.35\n",
        "#\n",
        "# plt.bar(x - width/2, baseline_scores, width, label='Baseline')\n",
        "# plt.bar(x + width/2, mlp_scores, width, label='MLP')\n",
        "# plt.xlabel('Metrics')\n",
        "# plt.ylabel('Score')\n",
        "# plt.title('Model Performance Comparison')\n",
        "# plt.xticks(x, metrics)\n",
        "# plt.legend()\n",
        "# plt.grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kwGA8VDF3szD"
      },
      "source": [
        "## Section 7: Analysis and Discussion\n",
        "\n",
        "Write your analysis (minimum 200 words)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yeqsGvSG3szD"
      },
      "outputs": [],
      "source": [
        "analysis_text = \"\"\"\n",
        "TODO: Write your analysis here (minimum 200 words)\n",
        "\n",
        "Address these questions:\n",
        "1. Which model performed better and by how much?\n",
        "2. Why do you think one model outperformed the other?\n",
        "3. What was the computational cost difference (training time)?\n",
        "4. Any surprising findings or challenges you faced?\n",
        "5. What insights did you gain about neural networks vs linear models?\n",
        "\n",
        "Write your thoughtful analysis here. Be specific and reference your actual results.\n",
        "Compare the metrics, discuss the trade-offs, and explain what you learned.\n",
        "\"\"\"\n",
        "\n",
        "print(f\"Analysis word count: {len(analysis_text.split())} words\")\n",
        "if len(analysis_text.split()) < 200:\n",
        "    print(\"⚠️  Warning: Analysis should be at least 200 words\")\n",
        "else:\n",
        "    print(\"✓ Analysis meets word count requirement\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nGvzhggS3szD"
      },
      "source": [
        "---\n",
        "---\n",
        "\n",
        "## ⭐ REQUIRED: Structured Output Function\n",
        "\n",
        "### **DO NOT MODIFY THE STRUCTURE BELOW**\n",
        "\n",
        "This function will be called by the auto-grader. Fill in all values accurately based on your actual results."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_5vp6uec3szD"
      },
      "outputs": [],
      "source": [
        "def get_assignment_results():\n",
        "    \"\"\"\n",
        "    Return all assignment results in structured format.\n",
        "\n",
        "    CRITICAL: Fill in ALL values based on your actual results!\n",
        "    This will be automatically extracted and validated.\n",
        "    \"\"\"\n",
        "\n",
        "    # Calculate loss convergence flags\n",
        "    baseline_initial_loss = 0.0  # TODO: baseline_model.loss_history[0]\n",
        "    baseline_final_loss = 0.0    # TODO: baseline_model.loss_history[-1]\n",
        "    mlp_initial_loss = 0.0       # TODO: mlp_model.loss_history[0]\n",
        "    mlp_final_loss = 0.0         # TODO: mlp_model.loss_history[-1]\n",
        "\n",
        "    results = {\n",
        "        # ===== Dataset Information =====\n",
        "        'dataset_name': dataset_name,\n",
        "        'dataset_source': dataset_source,\n",
        "        'n_samples': n_samples,\n",
        "        'n_features': n_features,\n",
        "        'problem_type': problem_type,\n",
        "        'problem_statement': problem_statement,\n",
        "\n",
        "        # ===== Evaluation Setup =====\n",
        "        'primary_metric': primary_metric,\n",
        "        'metric_justification': metric_justification,\n",
        "        'train_samples': train_samples,\n",
        "        'test_samples': test_samples,\n",
        "        'train_test_ratio': train_test_ratio,\n",
        "\n",
        "        # ===== Baseline Model Results =====\n",
        "        'baseline_model': {\n",
        "            'model_type': '',  # 'linear_regression', 'logistic_regression', or 'softmax_regression'\n",
        "            'learning_rate': 0.0,\n",
        "            'n_iterations': 0,\n",
        "            'initial_loss': baseline_initial_loss,\n",
        "            'final_loss': baseline_final_loss,\n",
        "            'training_time_seconds': baseline_training_time,\n",
        "\n",
        "            # Metrics (fill based on your problem type)\n",
        "            'test_accuracy': 0.0,      # For classification\n",
        "            'test_precision': 0.0,     # For classification\n",
        "            'test_recall': 0.0,        # For classification\n",
        "            'test_f1': 0.0,            # For classification\n",
        "            'test_mse': 0.0,           # For regression\n",
        "            'test_rmse': 0.0,          # For regression\n",
        "            'test_mae': 0.0,           # For regression\n",
        "            'test_r2': 0.0,            # For regression\n",
        "        },\n",
        "\n",
        "        # ===== MLP Model Results =====\n",
        "        'mlp_model': {\n",
        "            'architecture': mlp_architecture,\n",
        "            'n_hidden_layers': len(mlp_architecture) - 2 if len(mlp_architecture) > 0 else 0,\n",
        "            'total_parameters': 0,     # TODO: Calculate total weights + biases\n",
        "            'learning_rate': 0.0,\n",
        "            'n_iterations': 0,\n",
        "            'initial_loss': mlp_initial_loss,\n",
        "            'final_loss': mlp_final_loss,\n",
        "            'training_time_seconds': mlp_training_time,\n",
        "\n",
        "            # Metrics\n",
        "            'test_accuracy': 0.0,\n",
        "            'test_precision': 0.0,\n",
        "            'test_recall': 0.0,\n",
        "            'test_f1': 0.0,\n",
        "            'test_mse': 0.0,\n",
        "            'test_rmse': 0.0,\n",
        "            'test_mae': 0.0,\n",
        "            'test_r2': 0.0,\n",
        "        },\n",
        "\n",
        "        # ===== Comparison =====\n",
        "        'improvement': 0.0,            # MLP primary_metric - baseline primary_metric\n",
        "        'improvement_percentage': 0.0,  # (improvement / baseline) * 100\n",
        "        'baseline_better': False,       # True if baseline outperformed MLP\n",
        "\n",
        "        # ===== Analysis =====\n",
        "        'analysis': analysis_text,\n",
        "        'analysis_word_count': len(analysis_text.split()),\n",
        "\n",
        "        # ===== Loss Convergence Flags =====\n",
        "        'baseline_loss_decreased': baseline_final_loss < baseline_initial_loss,\n",
        "        'mlp_loss_decreased': mlp_final_loss < mlp_initial_loss,\n",
        "        'baseline_converged': False,  # Optional: True if converged\n",
        "        'mlp_converged': False,\n",
        "    }\n",
        "\n",
        "    return results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KuPELdxa3szE"
      },
      "source": [
        "## Test Your Output\n",
        "\n",
        "Run this cell to verify your results dictionary is complete and properly formatted."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gUipG0vJ3szE"
      },
      "outputs": [],
      "source": [
        "# Test the output\n",
        "import json\n",
        "\n",
        "try:\n",
        "    results = get_assignment_results()\n",
        "\n",
        "    print(\"=\"*70)\n",
        "    print(\"ASSIGNMENT RESULTS SUMMARY\")\n",
        "    print(\"=\"*70)\n",
        "    print(json.dumps(results, indent=2, default=str))\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "\n",
        "    # Check for missing values\n",
        "    missing = []\n",
        "    def check_dict(d, prefix=\"\"):\n",
        "        for k, v in d.items():\n",
        "            if isinstance(v, dict):\n",
        "                check_dict(v, f\"{prefix}{k}.\")\n",
        "            elif (v == 0 or v == \"\" or v == 0.0 or v == []) and \\\n",
        "                 k not in ['improvement', 'improvement_percentage', 'baseline_better',\n",
        "                          'baseline_converged', 'mlp_converged', 'total_parameters',\n",
        "                          'test_accuracy', 'test_precision', 'test_recall', 'test_f1',\n",
        "                          'test_mse', 'test_rmse', 'test_mae', 'test_r2']:\n",
        "                missing.append(f\"{prefix}{k}\")\n",
        "\n",
        "    check_dict(results)\n",
        "\n",
        "    if missing:\n",
        "        print(f\"⚠️  Warning: {len(missing)} fields still need to be filled:\")\n",
        "        for m in missing[:15]:  # Show first 15\n",
        "            print(f\"  - {m}\")\n",
        "        if len(missing) > 15:\n",
        "            print(f\"  ... and {len(missing)-15} more\")\n",
        "    else:\n",
        "        print(\"✅ All required fields are filled!\")\n",
        "        print(\"\\n🎉 You're ready to submit!\")\n",
        "        print(\"\\nNext steps:\")\n",
        "        print(\"1. Kernel → Restart & Clear Output\")\n",
        "        print(\"2. Kernel → Restart & Run All\")\n",
        "        print(\"3. Verify no errors\")\n",
        "        print(\"4. Save notebook\")\n",
        "        print(\"5. Rename as: YourStudentID_assignment.ipynb\")\n",
        "        print(\"6. Submit to LMS\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"❌ Error in get_assignment_results(): {str(e)}\")\n",
        "    print(\"\\nPlease fix the errors above before submitting.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tta_ZTtI3szE"
      },
      "source": [
        "---\n",
        "\n",
        "## 📤 Before Submitting - Final Checklist\n",
        "\n",
        "- [ ] **All TODO sections completed**\n",
        "- [ ] **Both models implemented from scratch** (no sklearn models!)\n",
        "- [ ] **get_assignment_results() function filled accurately**\n",
        "- [ ] **Loss decreases for both models**\n",
        "- [ ] **Analysis ≥ 200 words**\n",
        "- [ ] **All cells run without errors** (Restart & Run All)\n",
        "- [ ] **Visualizations created**\n",
        "- [ ] **File renamed correctly**: YourStudentID_assignment.ipynb\n",
        "\n",
        "---\n",
        "\n",
        "## ⏭️ What Happens Next\n",
        "\n",
        "After submission:\n",
        "1. ✅ Your notebook will be **auto-graded** (executes automatically)\n",
        "2. ✅ You'll receive a **verification quiz** (10 questions, 5 minutes)\n",
        "3. ✅ Quiz questions based on **YOUR specific results**\n",
        "4. ✅ Final score released after quiz validation\n",
        "\n",
        "**The verification quiz ensures you actually ran your code!**\n",
        "\n",
        "---\n",
        "\n",
        "**Good luck! 🚀**"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.0"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}